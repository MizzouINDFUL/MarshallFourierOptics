{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d87835-ed21-4534-940e-ef4fabcd8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard imports\n",
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from typing import Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "#PL imports\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms\n",
    "from pytorch_lightning.plugins import DDPPlugin\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import DataLoader, random_split, RandomSampler, Dataset\n",
    "\n",
    "#For PL warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff6307f-2acd-4718-8289-c4cf9a87e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Propagation_Layer(torch.nn.Module):\n",
    "    '''\n",
    "    A class for implementing the angular spectrum method (ASM) of wavefront propagation \n",
    "    for neural networks. Attributes used during training are registered as buffers per \n",
    "    PytorchLightning documentation.\n",
    "\n",
    "    ... \n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    params : dict\n",
    "        Dictionary of propagation parameters to fill out most of other attributes.\n",
    "    \n",
    "    batch_size : int, tensor\n",
    "        Batch sized used during training.\n",
    "\n",
    "    distance : float, tensor\n",
    "        Propagation distance between layers.\n",
    "\n",
    "    wavelength : float, tensor\n",
    "        Wavelength of illumination light.\n",
    "\n",
    "    Nx : int, tensor\n",
    "        Number of DOE/SLM 'pixel elements' in the x direction.\n",
    "    \n",
    "    Ny : int, tensor\n",
    "        Number of DOE/SLM 'pixel elements' in the y direction.\n",
    "\n",
    "    extent_x : float, tensor\n",
    "        Length of DOE/SLM in the x direction.\n",
    "\n",
    "    extent_y : float, tensor\n",
    "        Length of DOE/SLM in the y direction. \n",
    "   \n",
    "    pixel_pitch : float, tensor\n",
    "        Pitch (distance between) of DOE/SLM pixels.  \n",
    "\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    init_layer()\n",
    "        Initializes the propagation plane and propagation kernel for the ASM.\n",
    "\n",
    "    forward(wavefront, distance=None)\n",
    "        Performs the ASM and returns the resulting wavefront.\n",
    "    '''\n",
    "    def __init__(self, params, distance):\n",
    "        super().__init__()\n",
    "        self.distance = distance\n",
    "        self.params = params['propagator']\n",
    "        self.batch_size = params['lightning']['batch_size']\n",
    "        self.register_buffer('wavelength', torch.tensor(self.params['wavelength']))\n",
    "        #DOE/SLM Parameters\n",
    "        self.doe_params = self.params['pluto']\n",
    "        self.register_buffer('Nx', torch.tensor(self.doe_params['Nx']))\n",
    "        self.register_buffer('Ny', torch.tensor(self.doe_params['Ny']))\n",
    "        self.register_buffer('extent_x', torch.tensor(self.doe_params['x_extent']))   \n",
    "        self.register_buffer('extent_y', torch.tensor(self.doe_params['y_extent']))   \n",
    "        #Initialize the propagation layer. \n",
    "        self.init_layer()\n",
    " \n",
    "    def init_layer(self):\n",
    "        self.register_buffer('x', torch.linspace(-self.extent_x / 2, self.extent_x / 2, self.Nx))\n",
    "        self.register_buffer('y', torch.linspace(-self.extent_y / 2, self.extent_y / 2, self.Ny))\n",
    "\n",
    "        xx,yy = torch.meshgrid(self.x, self.y)\n",
    "        self.register_buffer('xx', xx.clone())\n",
    "        self.register_buffer('yy', yy.clone())\n",
    " \n",
    "        self.register_buffer('kx', torch.linspace(\n",
    "            -math.pi * torch.div(self.Nx, 2, rounding_mode='floor') / (self.extent_x / 2), \n",
    "            math.pi * torch.div(self.Nx, 2, rounding_mode='floor') / (self.extent_x / 2),\n",
    "            self.Nx\n",
    "        ))\n",
    "        self.register_buffer('ky', torch.linspace(\n",
    "            -math.pi * torch.div(self.Ny, 2, rounding_mode='floor') / (self.extent_y / 2), \n",
    "            math.pi * torch.div(self.Ny, 2, rounding_mode='floor') / (self.extent_y / 2),\n",
    "            self.Ny\n",
    "        ))\n",
    "        kxx, kyy =  torch.meshgrid(self.kx, self.ky)\n",
    "        \n",
    "        self.register_buffer('kxx', kxx.clone())\n",
    "        self.register_buffer('kyy', kyy.clone()) \n",
    "        self.register_buffer('kz', torch.sqrt((2 * math.pi / self.wavelength) ** 2 - self.kxx ** 2 - self.kyy ** 2))\n",
    "\n",
    "    def forward(self, wavefront, distance = None):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        wavefront : float, tensor (Batch, Channel(2), Width, Height)\n",
    "            Input wavefront to the layer. Channels are for the amplitude and phase of the\n",
    "            wavefront respectively. \n",
    "\n",
    "        distance : float, tensor\n",
    "            Distance of propation from current layer to the next. \n",
    "        '''\n",
    "\n",
    "        if distance is not None:\n",
    "            self.distance = torch.tensor(distance)\n",
    "   \n",
    "        amplitude = wavefront[:,0,:,:]\n",
    "        phase = wavefront[:,1,:,:]\n",
    "\n",
    "        E = amplitude[:,:,:] * torch.exp(1j * phase[:,:,:])\n",
    " \n",
    "        #Get the angular spectrum at the current plane\n",
    "        fft_c = torch.fft.fft2(E)\n",
    "        c = torch.fft.fftshift(fft_c)\n",
    "\n",
    "        #Multiply the angular spectrum by the propagation transfer function\n",
    "        c_z = c * torch.exp(1j * self.kz * self.distance).to(c.device)\n",
    "\n",
    "        #Compute the new wavefront\n",
    "        E = torch.fft.ifft2(torch.fft.ifftshift(c_z))\n",
    "\n",
    "        amplitude = torch.unsqueeze(torch.abs(E), 1)\n",
    "        phase = torch.unsqueeze(torch.angle(E), 1)\n",
    "\n",
    "        return torch.cat((amplitude, phase) , 1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e432ba-b695-443d-a389-499a434ddb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cgh_overfit_dataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.load_data()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.dataset['sample']))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        sample = self.dataset['sample'][idx]\n",
    "        target = self.dataset['target'][idx]\n",
    "        \n",
    "        return(sample,target)\n",
    "\n",
    "    def load_data(self):\n",
    "        image = np.abs(np.load(self.data_path))\n",
    "        image = torch.tensor(image).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "        target = image / torch.max(image)\n",
    "        \n",
    "        sample_amplitude = torch.ones(1,1,445,445)\n",
    "        sample_phase = torch.ones(1,1,445,445)\n",
    "        \n",
    "        sample_wavefront = torch.cat((sample_amplitude, sample_phase), dim=1)\n",
    "        \n",
    "        self.dataset = {'sample':sample_wavefront, 'target':target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb0418-f6b9-4f21-824d-9f46570476c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phase_Optimization(pl.LightningModule):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.Nx = torch.tensor(params['propagator']['pluto']['Nx'])\n",
    "        self.Ny = torch.tensor(params['propagator']['pluto']['Ny'])\n",
    "        self.distance = torch.tensor(params['propagator']['distance'])\n",
    "        self.wavelength = torch.tensor(params['propagator']['wavelength'])\n",
    "        self.lr = params['lightning']['lr']\n",
    "        self.batch_size = params['lightning']['batch_size']\n",
    "        #Layers\n",
    "        self.init_diffractive_layers(params)\n",
    "        self.init_propagation_layers(params) \n",
    "        \n",
    "    def init_diffractive_layers(self, params):\n",
    "        params = params['model']\n",
    "        num_layers = params['num_layers']\n",
    "\n",
    "        self.initial_phases = [torch.nn.Parameter(torch.from_numpy(np.ones((1,1,self.Nx, self.Ny)))) for _ in range(num_layers)]\n",
    "        self.initial_amplitudes = [torch.nn.Parameter(torch.from_numpy(np.ones((1,1,self.Nx, self.Ny)))) for _ in range(num_layers)]\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            self.initial_amplitudes[i].requires_grad = True\n",
    "            self.initial_phases[i].requires_grad = False\n",
    "            self.register_parameter(f\"phase_{i}\", self.initial_phases[i])\n",
    "            self.register_parameter(f\"amplitude_{i}\", self.initial_amplitudes[i])\n",
    "            \n",
    "    def init_propagation_layers(self, params):\n",
    "        num_layers = params['model']['num_layers']\n",
    "        self.prop_layers = [Propagation_Layer(params, self.distance) for _ in range(num_layers)]\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def criterion(self, x, y):\n",
    "        loss = torch.nn.functional.mse_loss(x, y)\n",
    "        return(loss)\n",
    "    \n",
    "    #======================================\n",
    "    # Custom Functions\n",
    "    #======================================\n",
    "    def apply_transmission(self, wavefront, layer):\n",
    "        wavefront_amplitude = wavefront[:,0,:,:]\n",
    "        wavefront_phase = wavefront[:,1,:,:]\n",
    "        modified_amplitude = torch.squeeze(wavefront_amplitude * layer[0])\n",
    "        modified_phase = torch.squeeze(wavefront_phase + layer[1])\n",
    "        temp1 = torch.unsqueeze(modified_amplitude, dim=0)\n",
    "        temp2 = torch.unsqueeze(modified_phase, dim=0)\n",
    "\n",
    "        output = torch.cat((temp1,temp2),dim=0)\n",
    "\n",
    "        return output.unsqueeze(dim=0)\n",
    "    \n",
    "    #======================================\n",
    "    # Dataset Things\n",
    "    #======================================\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.dataset = cgh_overfit_dataset('../images/hexagonal_dp.npy')\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset, batch_size=self.batch_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #Apply Transmission for layer 0\n",
    "        amplitude = nn.functional.sigmoid(self.amplitude_0)\n",
    "        self.u0 = self.apply_transmission(x, (amplitude, self.phase_0))\n",
    "        \n",
    "        #Propagate\n",
    "        self.E0 = self.prop_layers[0].forward(self.u0)\n",
    "        \n",
    "        return self.E0\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x,y = batch\n",
    "        y = y.double()\n",
    "        wavefront = self(x).squeeze()\n",
    "        wavefront_ = wavefront[0] * torch.exp(1j * wavefront[1])\n",
    "        image = torch.abs(wavefront_)\n",
    "\n",
    "        loss = self.criterion(image,y)\n",
    "\n",
    "        return {'loss':loss, 'pred_wavefront':wavefront, 'target':y}\n",
    "    \n",
    "    def training_step_end(self, outputs):\n",
    "        self.wavefront = outputs['pred_wavefront']\n",
    "        self.target = outputs['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9e847f-bf38-430a-9527-b53ceba7c153",
   "metadata": {},
   "source": [
    "# Begin Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5aef10-ea74-408b-9a23-5212033936c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yaml.load(open('config.yaml'), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fbb60b-491e-4c69-8b1f-c72cd0bf25cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Phase_Optimization(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e02e7b-3419-4bc5-8d98-297769e561af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_params = params['trainer']\n",
    "\n",
    "if(trainer_params['gpus'] == 'None'):\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = trainer_params['max_epoch'],\n",
    "        progress_bar_refresh_rate = 10\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    print(\"GPU support is not provided for this example\")\n",
    "    # You can experiment at your own risk with GPUs - this is not validated for\n",
    "    # this example.+\n",
    "    # trainer = pl.Trainer(\n",
    "    #   gpus = trainer_params['gpus'],\n",
    "    #    max_epochs = trainer_params['max_epoch'],\n",
    "    #    accelerator = trainer_params['accelerator'],\n",
    "    #    plugins = DDPPlugin(find_unused_parameters = True),\n",
    "    #    progress_bar_refresh_rate = 10\n",
    "    #)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5882b4d-f05f-4484-8f39-71fdb433eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavefront = model.wavefront.detach().cpu().squeeze()\n",
    "wavefront = wavefront[0] * torch.exp(1j * wavefront[1])\n",
    "prediction = torch.abs(wavefront).squeeze().numpy()\n",
    "\n",
    "target = model.target.squeeze().detach().cpu().numpy()\n",
    "\n",
    "difference = np.abs(prediction - target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085650e-ef1b-47e0-a1f6-e59dc68696a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1,ax1 = plt.subplots(1,3,figsize=(10,4))\n",
    "ax1[0].imshow(target)\n",
    "ax1[0].set_title(\"Ideal Diffraction Pattern\")\n",
    "ax1[1].imshow(prediction)\n",
    "ax1[1].set_title(\"Predicted Diffraction Pattern\")\n",
    "ax1[2].imshow(difference)\n",
    "ax1[2].set_title(\"| Prediction - Ideal |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7578cdd1-18bd-4730-9410-d33a422a1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_amplitude = nn.functional.sigmoid(model.amplitude_0).squeeze().detach().cpu()\n",
    "predicted_amplitude = predicted_amplitude / torch.max(predicted_amplitude)\n",
    "threshold = 0.5\n",
    "predicted_amplitude_thresh = (predicted_amplitude > threshold).numpy().astype('float')\n",
    "\n",
    "\n",
    "real_amplitude = cv2.imread('../images/hexagon_grating.jpg')\n",
    "real_amplitude = np.pad(real_amplitude, 200, mode='constant')\n",
    "\n",
    "real_amplitude = cv2.resize(real_amplitude, dsize=(445, 445), interpolation=cv2.INTER_CUBIC)\n",
    "real_amplitude = np.array(real_amplitude).sum(axis=2).astype(float)\n",
    "real_amplitude = real_amplitude / np.max(real_amplitude)\n",
    "\n",
    "\n",
    "difference = np.abs(predicted_amplitude_thresh - real_amplitude)\n",
    "#difference = predicted_amplitude - real_amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f3ccd-c002-4c23-a933-1245dbfbd5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2,ax2 = plt.subplots(1)\n",
    "ax2.imshow(predicted_amplitude)\n",
    "ax2.set_title(\"Optimized / Predicted Aperture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9dff44-6453-4ec7-bb90-9ef23ee5ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3,ax3 = plt.subplots(1,3,figsize=(10,4))\n",
    "im0 = ax3[0].imshow(real_amplitude)\n",
    "ax3[0].set_title(\"Ideal Aperture\")\n",
    "\n",
    "im1 = ax3[1].imshow(predicted_amplitude_thresh)\n",
    "ax3[1].set_title(f\"Predicted Aperture \\nThreshold={threshold}\")\n",
    "\n",
    "im2 = ax3[2].imshow(difference)\n",
    "ax3[2].set_title(\"| Prediction - Ideal |\")\n",
    "\n",
    "fig3.subplots_adjust(left=0.1, bottom = 0.1)\n",
    "#Define some sliders\n",
    "threshold_slider_ax = fig3.add_axes([0.2, 0.08, 0.6, 0.04])\n",
    "threshold_slider = Slider(threshold_slider_ax, 'Threshold', 0., 1., valinit=threshold)\n",
    "threshold_slider.label.set_size(12)\n",
    "\n",
    "def sliders_on_changed(val):\n",
    "    if threshold_slider.val == 1:\n",
    "        predicted_amlitude_thresh = predicted_amplitude\n",
    "    else:\n",
    "        predicted_amplitude_thresh = (predicted_amplitude > threshold_slider.val).numpy().astype('float')\n",
    "        \n",
    "    difference = np.abs(predicted_amplitude_thresh - real_amplitude)\n",
    "    ax3[1].set_title(f\"Predicted Aperture \\nThreshold={round(threshold_slider.val, 3)}\")\n",
    "    im1.set_data(predicted_amplitude_thresh)\n",
    "    im2.set_data(difference)\n",
    "    fig3.canvas.draw_idle()\n",
    "    \n",
    "threshold_slider.on_changed(sliders_on_changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b291a309-940e-43c0-a5e9-54ed48d3c2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
